"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.Sitemap = void 0;
const tslib_1 = require("tslib");
const node_stream_1 = require("node:stream");
const node_string_decoder_1 = require("node:string_decoder");
const node_zlib_1 = require("node:zlib");
const log_1 = tslib_1.__importDefault(require("@apify/log"));
const sax_1 = tslib_1.__importDefault(require("sax"));
class ParsingState {
    constructor() {
        Object.defineProperty(this, "sitemapUrls", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: []
        });
        Object.defineProperty(this, "urls", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: []
        });
        Object.defineProperty(this, "visitedSitemapUrls", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: []
        });
        Object.defineProperty(this, "context", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "loc", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: false
        });
    }
    resetContext() {
        this.context = undefined;
        this.loc = false;
    }
}
class SitemapTxtParser extends node_stream_1.Writable {
    constructor(parsingState, onEnd) {
        super();
        Object.defineProperty(this, "parsingState", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: parsingState
        });
        Object.defineProperty(this, "onEnd", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: onEnd
        });
        Object.defineProperty(this, "decoder", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: new node_string_decoder_1.StringDecoder('utf8')
        });
        Object.defineProperty(this, "buffer", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: ''
        });
    }
    processBuffer(input, finalize) {
        this.buffer += input;
        if (finalize || this.buffer.includes('\n')) {
            const parts = this.buffer
                .split('\n')
                .map((part) => part.trim())
                .filter((part) => part.length > 0);
            if (finalize) {
                this.parsingState.urls.push(...parts);
                this.buffer = '';
            }
            else if (parts.length > 0) {
                this.parsingState.urls.push(...parts.slice(0, -1));
                this.buffer = parts.at(-1);
            }
        }
    }
    _write(chunk, _encoding, callback) {
        this.processBuffer(this.decoder.write(chunk), false);
        callback();
    }
    _final(callback) {
        this.processBuffer(this.decoder.end(), true);
        callback();
        this.onEnd();
    }
}
/**
 * Loads one or more sitemaps from given URLs, following references in sitemap index files, and exposes the contained URLs.
 *
 * **Example usage:**
 * ```javascript
 * // Load a sitemap
 * const sitemap = await Sitemap.load(['https://example.com/sitemap.xml', 'https://example.com/sitemap_2.xml.gz']);
 *
 * // Enqueue all the contained URLs (including those from sub-sitemaps from sitemap indexes)
 * await crawler.addRequests(sitemap.urls);
 * ```
 */
class Sitemap {
    constructor(urls) {
        Object.defineProperty(this, "urls", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: urls
        });
    }
    static createXmlParser(parsingState, onEnd, onError) {
        const parser = sax_1.default.createStream(true);
        parser.on('opentag', (node) => {
            if (node.name === 'loc' && parsingState.context !== undefined) {
                parsingState.loc = true;
            }
            if (node.name === 'urlset') {
                parsingState.context = 'urlset';
            }
            if (node.name === 'sitemapindex') {
                parsingState.context = 'sitemapindex';
            }
        });
        parser.on('closetag', (name) => {
            if (name === 'loc') {
                parsingState.loc = false;
            }
        });
        parser.on('text', (text) => {
            if (parsingState.loc) {
                if (parsingState.context === 'sitemapindex') {
                    if (!parsingState.visitedSitemapUrls.includes(text)) {
                        parsingState.sitemapUrls.push(text);
                    }
                }
                if (parsingState.context === 'urlset') {
                    parsingState.urls.push(text);
                }
            }
        });
        parser.on('end', onEnd);
        parser.on('error', onError);
        return parser;
    }
    /**
     * Try to load sitemap from the most common locations - `/sitemap.xml` and `/sitemap.txt`.
     * For loading based on `Sitemap` entries in `robots.txt`, the {@apilink RobotsFile} class should be used.
     * @param url The domain URL to fetch the sitemap for.
     * @param proxyUrl A proxy to be used for fetching the sitemap file.
     */
    static async tryCommonNames(url, proxyUrl) {
        const sitemapUrls = [];
        const sitemapUrl = new URL(url);
        sitemapUrl.search = '';
        sitemapUrl.pathname = '/sitemap.xml';
        sitemapUrls.push(sitemapUrl.toString());
        sitemapUrl.pathname = '/sitemap.txt';
        sitemapUrls.push(sitemapUrl.toString());
        return Sitemap.load(sitemapUrls, proxyUrl);
    }
    /**
     * Fetch sitemap content from given URL or URLs and return URLs of referenced pages.
     * @param urls sitemap URL(s)
     * @param proxyUrl URL of a proxy to be used for fetching sitemap contents
     */
    static async load(urls, proxyUrl) {
        const { gotScraping } = await import('got-scraping');
        const parsingState = new ParsingState();
        parsingState.sitemapUrls = Array.isArray(urls) ? urls : [urls];
        while (parsingState.sitemapUrls.length > 0) {
            let sitemapUrl = parsingState.sitemapUrls.pop();
            parsingState.visitedSitemapUrls.push(sitemapUrl);
            parsingState.resetContext();
            try {
                const sitemapStream = await new Promise((resolve, reject) => {
                    const request = gotScraping.stream({ url: sitemapUrl, proxyUrl, method: 'GET' });
                    request.on('response', () => resolve(request));
                    request.on('error', reject);
                });
                if (sitemapStream.response.statusCode === 200) {
                    await new Promise((resolve, reject) => {
                        let stream = sitemapStream;
                        if (sitemapUrl.endsWith('.gz')) {
                            stream = stream.pipe((0, node_zlib_1.createGunzip)());
                            sitemapUrl = sitemapUrl.substring(0, sitemapUrl.length - 3);
                        }
                        const parser = (() => {
                            const contentType = sitemapStream.response.headers['content-type'];
                            if (contentType === 'text/xml' || sitemapUrl.endsWith('.xml')) {
                                return Sitemap.createXmlParser(parsingState, () => resolve(undefined), reject);
                            }
                            if (contentType === 'text/plain' || sitemapUrl.endsWith('.txt')) {
                                return new SitemapTxtParser(parsingState, () => resolve(undefined));
                            }
                            throw new Error('Unsupported sitemap content type');
                        })();
                        stream.pipe(parser);
                    });
                }
            }
            catch (e) {
                log_1.default.warning(`Malformed sitemap content: ${sitemapUrl}`);
            }
        }
        return new Sitemap(parsingState.urls);
    }
}
exports.Sitemap = Sitemap;
//# sourceMappingURL=sitemap.js.map